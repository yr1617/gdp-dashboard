import streamlit as st
import requests
import xml.etree.ElementTree as ET
from datetime import datetime
import math # í˜ì´ì§€ ê³„ì‚°ì„ ìœ„í•´ math ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

# --------------------------------------------------------------------------
# 1. API ì„¤ì • ë° ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©)
# --------------------------------------------------------------------------

API_KEY = "0b594b395a0248a3a0a68f3b79483427"
BASE_URL = f"https://www.career.go.kr/cnet/openapi/getOpenApi?apiKey={API_KEY}&svcType=api&svcCode=SCHOOL&contentType=xml&gubun=high_list"

# @st.cache_dataëŠ” ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ ë¡œë“œí•  ë•Œ ë§¤ë²ˆ ìƒˆë¡œ ì‹¤í–‰ë˜ì–´ì•¼ í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìºì‹œ ëŒ€ì‹  ì „ì²´ ê²°ê³¼ë¥¼ ìºì‹œí•©ë‹ˆë‹¤.
@st.cache_data(ttl=3600) # 1ì‹œê°„ ë™ì•ˆ ì „ì²´ ê²°ê³¼ë¥¼ ìºì‹±
def load_all_school_data():
    """
    í˜ì´ì§€ë„¤ì´ì…˜ì„ í†µí•´ ëª¨ë“  í•™êµ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    """
    all_schools = []
    page = 1
    per_page = 100 # í•œ ë²ˆì— 100ê°œì”© ìš”ì²­í•˜ëŠ” ê²ƒì´ ì•ˆì •ì ì…ë‹ˆë‹¤.
    
    try:
        # 1. ì²« í˜ì´ì§€ë¥¼ ìš”ì²­í•˜ì—¬ ì „ì²´ ë°ì´í„° ìˆ˜ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
        first_response = requests.get(f"{BASE_URL}&perPage={per_page}&page={page}")
        first_response.raise_for_status()
        root = ET.fromstring(first_response.content)
        
        total_count_element = root.find('.//totalCount')
        if total_count_element is None:
            st.error("API ì‘ë‹µì—ì„œ ì „ì²´ ë°ì´í„° ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        total_count = int(total_count_element.text)
        if total_count == 0:
            return []

        # 2. ì „ì²´ í˜ì´ì§€ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        total_pages = math.ceil(total_count / per_page)
        
        st.info(f"ì´ {total_count}ê°œ ë°ì´í„°ë¥¼ {total_pages} í˜ì´ì§€ì— ê±¸ì³ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
        progress_bar = st.progress(0, text="ë°ì´í„° ë¡œë”© ì¤‘...")

        # 3. ëª¨ë“  í˜ì´ì§€ë¥¼ ìˆœíšŒí•˜ë©° ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        for page in range(1, total_pages + 1):
            response = requests.get(f"{BASE_URL}&perPage={per_page}&page={page}")
            response.raise_for_status()
            root = ET.fromstring(response.content)
            
            for content in root.findall('.//content'):
                school_info = {
                    'schoolName': content.findtext('schoolName'), 'region': content.findtext('region'),
                    'totalCount': content.findtext('totalCount'), 'major': content.findtext('major'),
                    'subject': content.findtext('subject'), 'chart': content.findtext('chart'),
                    'cert': content.findtext('cert')
                }
                all_schools.append(school_info)
            
            # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
            progress_bar.progress(page / total_pages, text=f"ë°ì´í„° ë¡œë”© ì¤‘... ({page}/{total_pages} í˜ì´ì§€)")

        progress_bar.empty() # ë¡œë”© ì™„ë£Œ í›„ í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì œê±°
        return all_schools

    except requests.exceptions.RequestException as e:
        st.error(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None
    except (ET.ParseError, TypeError, ValueError) as e:
        st.error(f"ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# --------------------------------------------------------------------------
# 2. Streamlit ì•± UI êµ¬ì„± (ì´í•˜ ë™ì¼)
# --------------------------------------------------------------------------

st.set_page_config(page_title="ì „êµ­ íŠ¹ì„±í™”ê³  í•™ê³¼ ê²€ìƒ‰", page_icon="ğŸ«", layout="wide")

if 'search_history' not in st.session_state:
    st.session_state.search_history = []

st.title("ğŸ« ì „êµ­ íŠ¹ì„±í™”/íŠ¹ìˆ˜ëª©ì  ê³ ë“±í•™êµ í•™ê³¼ ê²€ìƒ‰")

# --- ë°ì´í„° ë¡œë“œ ---
school_data = load_all_school_data()

if school_data is not None: # ë°ì´í„°ê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ Noneë§Œ ì²´í¬
    st.success(f"âœ… ì´ {len(school_data)}ê°œì˜ í•™êµ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    
    search_query = st.text_input(
        label="ê¶ê¸ˆí•œ í•™ê³¼ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë””ìì¸, í”„ë¡œê·¸ë˜ë°, ì¡°ë¦¬)",
        placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”."
    )

    if search_query:
        if search_query not in st.session_state.search_history:
            now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            st.session_state.search_history.insert(0, f"[{now}] {search_query}")

        results = [school for school in school_data if school['major'] and search_query.lower() in school['major'].lower()]

        st.divider()

        if results:
            st.success(f"'{search_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: ì´ {len(results)}ê±´")
            for item in results:
                with st.expander(f"**{item['schoolName']}** - {item['major']}"):
                    st.markdown(f"**ğŸ« í•™êµëª…:** {item['schoolName']} ({item['region']})")
                    st.markdown(f"**ğŸ“š í•™ê³¼ëª…:** {item['major']}")
                    st.markdown(f"**ğŸ“– ë°°ìš°ëŠ” ë‚´ìš©:** {item['subject']}")
                    st.markdown(f"**ğŸ“ ì¡¸ì—… í›„ ì§„ë¡œ:** {item['chart']}")
                    st.markdown(f"**ğŸ“œ ì·¨ë“ ê°€ëŠ¥ ìê²©ì¦:** {item['cert']}")
        else:
            st.warning(f"'{search_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.")
else:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


with st.sidebar:
    st.header("ğŸ” ê²€ìƒ‰ ê¸°ë¡")
    if st.session_state.search_history:
        for record in st.session_state.search_history:
            st.text(record)
    else:
        st.info("ì•„ì§ ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.divider()
    st.caption("Powered by Streamlit & CareerNet API")
    