import streamlit as st
import requests
import xml.etree.ElementTree as ET
from datetime import datetime
import time

# --------------------------------------------------------------------------
# 1. API ì„¤ì • ë° ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ì¤‘ë³µ ë°ì´í„° ê°ì§€ ê¸°ëŠ¥ ì¶”ê°€)
# --------------------------------------------------------------------------

API_KEY = "0b594b395a0248a3a0a68f3b79483427"
BASE_URL = f"https://www.career.go.kr/cnet/openapi/getOpenApi?apiKey={API_KEY}&svcType=api&svcCode=SCHOOL&contentType=xml&gubun=high_list"

@st.cache_data(ttl=3600)
def load_all_school_data_definitive():
    """
    ì¤‘ë³µ ë°ì´í„° ê°ì§€ ë¡œì§ì„ ì¶”ê°€í•˜ì—¬ ë¬´í•œ ë£¨í”„ë¥¼ ë°©ì§€í•˜ëŠ” ê°€ì¥ ì•ˆì •ì ì¸ ìµœì¢… í•¨ìˆ˜
    """
    all_schools = []
    page = 1
    per_page = 100
    previous_page_content = None # ì´ì „ í˜ì´ì§€ ë‚´ìš©ê³¼ ë¹„êµí•˜ê¸° ìœ„í•œ ë³€ìˆ˜

    with st.spinner('ì „ì²´ í•™êµ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ë¬´í•œ ë£¨í”„ ë°©ì§€ ê¸°ëŠ¥ ì‘ë™ ì¤‘)'):
        while True:
            try:
                time.sleep(0.05) # ì„œë²„ì— ë¶€ë‹´ì„ ì£¼ì§€ ì•Šê¸° ìœ„í•œ ìµœì†Œí•œì˜ ì§€ì—°
                response = requests.get(f"{BASE_URL}&perPage={per_page}&page={page}")
                response.raise_for_status()
                
                # í˜„ì¬ í˜ì´ì§€ì˜ ì›ë³¸ XML í…ìŠ¤íŠ¸ë¥¼ ì €ì¥
                current_page_content = response.content
                
                # [í•µì‹¬ ë¡œì§] í˜„ì¬ í˜ì´ì§€ ë‚´ìš©ì´ ì´ì „ í˜ì´ì§€ì™€ ë™ì¼í•˜ë©´, ì¤‘ë³µì´ë¯€ë¡œ ì¤‘ë‹¨
                if current_page_content == previous_page_content:
                    break
                
                root = ET.fromstring(current_page_content)
                contents = root.findall('.//content')

                if not contents:
                    break
                
                for content in contents:
                    school_info = {
                        'schoolName': content.findtext('schoolName'), 'region': content.findtext('region'),
                        'totalCount': content.findtext('totalCount'), 'major': content.findtext('major'),
                        'subject': content.findtext('subject'), 'chart': content.findtext('chart'),
                        'cert': content.findtext('cert')
                    }
                    all_schools.append(school_info)
                
                # ë‹¤ìŒ ë£¨í”„ë¥¼ ìœ„í•´ í˜„ì¬ í˜ì´ì§€ ë‚´ìš©ì„ previous_page_contentì— ì €ì¥
                previous_page_content = current_page_content
                page += 1

            except requests.exceptions.RequestException as e:
                st.error(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return None
            except ET.ParseError as e:
                st.error(f"XML ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                return None
    
    return all_schools

# --------------------------------------------------------------------------
# 2. Streamlit ì•± UI êµ¬ì„± (ì´í•˜ ë™ì¼)
# --------------------------------------------------------------------------

st.set_page_config(page_title="ì „êµ­ íŠ¹ì„±í™”ê³  í•™ê³¼ ê²€ìƒ‰", page_icon="ğŸ«", layout="wide")

if 'search_history' not in st.session_state:
    st.session_state.search_history = []

st.title("ğŸ« ì „êµ­ íŠ¹ì„±í™”/íŠ¹ìˆ˜ëª©ì  ê³ ë“±í•™êµ í•™ê³¼ ê²€ìƒ‰")

school_data = load_all_school_data_definitive()

if school_data is not None:
    st.success(f"âœ… ì´ {len(school_data)}ê°œì˜ í•™êµ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    
    search_query = st.text_input(
        label="ê¶ê¸ˆí•œ í•™ê³¼ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë””ìì¸, í”„ë¡œê·¸ë˜ë°, ì¡°ë¦¬)",
        placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”."
    )

    if search_query:
        if search_query not in st.session_state.search_history:
            now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            st.session_state.search_history.insert(0, f"[{now}] {search_query}")

        results = [school for school in school_data if school['major'] and search_query.lower() in school['major'].lower()]

        st.divider()

        if results:
            st.success(f"'{search_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: ì´ {len(results)}ê±´")
            for item in results:
                with st.expander(f"**{item['schoolName']}** - {item['major']}"):
                    st.markdown(f"**ğŸ« í•™êµëª…:** {item['schoolName']} ({item['region']})")
                    st.markdown(f"**ğŸ“š í•™ê³¼ëª…:** {item['major']}")
                    st.markdown(f"**ğŸ“– ë°°ìš°ëŠ” ë‚´ìš©:** {item['subject']}")
                    st.markdown(f"**ğŸ“ ì¡¸ì—… í›„ ì§„ë¡œ:** {item['chart']}")
                    st.markdown(f"**ğŸ“œ ì·¨ë“ ê°€ëŠ¥ ìê²©ì¦:** {item['cert']}")
        else:
            st.warning(f"'{search_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.")
else:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


with st.sidebar:
    st.header("ğŸ” ê²€ìƒ‰ ê¸°ë¡")
    if st.session_state.search_history:
        for record in st.session_state.search_history:
            st.text(record)
    else:
        st.info("ì•„ì§ ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.divider()
    st.caption("Powered by Streamlit & CareerNet API")
    